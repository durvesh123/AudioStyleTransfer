{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Transfer Using Trained CNN On Spectrograms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a CNN on Image Spectrograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% run audio_utils.ipynb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from IPython.display import Audio, display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing:\n",
    "### We first trained a CNN on audio classification using  dataset from https://datahack.analyticsvidhya.com/contest/practice-problem-urban-sound-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting raw audio samples from .wav to 2-D spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofwav=[]\n",
    "\n",
    "def load_wav(path):\n",
    "    for dirname, subdir, filelist in os.walk(path):\n",
    "        for filename in filelist:\n",
    "            if '.wav' in filename.lower():\n",
    "                listofwav.append(os.path.join(dirname,filename))\n",
    "    return listofwav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_utils = AudioUtils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.load('saved_weights.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y_index = []\n",
    "wav = load_wav('train/Train/')\n",
    "for i in range(len(listofwav)):\n",
    "    print(i)\n",
    "    temp = audio_utils.wave_to_spectrogram(listofwav[i])[0]\n",
    "    if temp.shape[1] == 173:\n",
    "        X.append(temp)\n",
    "        y_index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.zeros((len(X),1025,173,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X)):\n",
    "    X[i] = X[i].reshape(X[i].shape[0], X[i].shape[1], 1)\n",
    "    X_data[i] = X[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('training_spectrograms_X',X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.load('training_spectrograms_X.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_1 = X_data[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('train/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(row):\n",
    "    label = row.Class\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train.apply(parser, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "y = np.array(temp.tolist())\n",
    "\n",
    "lb = LabelEncoder()\n",
    "\n",
    "y = np_utils.to_categorical(lb.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data=np.zeros((len(y_index),10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_index)):\n",
    "    y_data[i] = y[y_index[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = np.load('training_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_1 = y_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('y_data_1',y_data_1)\n",
    "np.save('X_data_1',X_data_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Sequential Model using Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(5,kernel_size = 3 ,activation = 'relu',input_shape=(1025,173,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(10,kernel_size = 3, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(20,kernel_size = 3, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(30,kernel_size = 3, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1024, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(512, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss = 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_data_1,y_data_1,epochs = 10,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_filename = \"/Users/durveshvedak/Desktop/Fall 2018/Deep Learning/AudioTrainedNetwork/Results/Shallow CNN/Result 4/laser.wav\"\n",
    "style_filename = \"applause2.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(content_filename))\n",
    "display(Audio(style_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_utils = AudioUtils()\n",
    "a_content, sampling_rate = audio_utils.wave_to_spectrogram(content_filename,2048)\n",
    "a_style, sampling_rate = audio_utils.wave_to_spectrogram(style_filename,2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_time = a_content.shape[1] # considering time domain as samples\n",
    "n_channels_frequency = a_content.shape[0] # considering frequency domain as channels\n",
    "a_style = a_style[:n_channels_frequency, :n_samples_time] # making sure style and content tensors have same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_style.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotting style and content spectrogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Content')\n",
    "plt.imshow(a_content[:400,:])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Style')\n",
    "plt.imshow(a_style[:300,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_style.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(1,a_content.shape[0],a_content.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_content = a_content.reshape((1,a_content.shape[0],a_content.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_content_tf = np.ascontiguousarray(a_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_style = a_style.reshape((1,a_style.shape[0],a_style.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_style_tf = np.ascontiguousarray(a_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = np.load('layer_1.npy')\n",
    "layer_2 = np.load('layer_2.npy')\n",
    "layer_3 = np.load('layer_3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = layer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_2 = layer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default(), g.device('/cpu:0'), tf.Session() as sess:\n",
    "    y = tf.placeholder('float32', [1,n_channels_frequency,n_samples_time,1], name=\"y\")\n",
    "    kernel_tf = tf.constant(kernel, name=\"kernel\", dtype='float32')\n",
    "    conv = tf.nn.conv2d(\n",
    "            y,\n",
    "            kernel_tf,\n",
    "            strides=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "            name=\"conv\")\n",
    "    \n",
    "    kernel_tf_2 = tf.constant(kernel_2, name=\"kernel_2\", dtype='float32')\n",
    "    \n",
    "    conv_2 = tf.nn.conv2d(\n",
    "            conv,\n",
    "            kernel_tf_2,\n",
    "            strides=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "            name=\"conv_2\")\n",
    "    \n",
    "    net = tf.nn.relu(conv_2)\n",
    "    content_features = net.eval(feed_dict={y: a_content})\n",
    "    style_features = net.eval(feed_dict={y: a_style})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.reshape(style_features,(style_features.shape[1] * style_features.shape[2],10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_gram = np.matmul(features.T, features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = None\n",
    "with tf.Graph().as_default():\n",
    "    x = x = tf.Variable(a_style, name=\"x\")\n",
    "    #x = tf.Variable(np.random.randn(1,n_channels_frequency,n_samples_time,1).astype(np.float32)*1e-3, name=\"x\")\n",
    "    \n",
    "    kernel_tf = tf.constant(kernel, name=\"kernel\", dtype='float32')\n",
    "    conv = tf.nn.conv2d(\n",
    "        x,\n",
    "        kernel_tf,\n",
    "        strides=[1, 1, 1, 1],\n",
    "        padding=\"VALID\",\n",
    "        name=\"conv\")\n",
    "    \n",
    "    kernel_tf_2 = tf.constant(kernel_2, name=\"kernel_2\", dtype='float32')\n",
    "    \n",
    "    conv_2 = tf.nn.conv2d(\n",
    "            conv,\n",
    "            kernel_tf_2,\n",
    "            strides=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "            name=\"conv_2\")\n",
    "    \n",
    "    net = tf.nn.relu(conv_2)\n",
    "    content_loss = tf.nn.l2_loss(\n",
    "            net - content_features)\n",
    "\n",
    "    style_loss = 0\n",
    "\n",
    "\n",
    "    feats = tf.reshape(net,(style_features.shape[1] * style_features.shape[2],10))\n",
    "    gram = tf.matmul(tf.transpose(feats), feats) \n",
    "    gram = gram * 0.001\n",
    "    style_loss = tf.nn.l2_loss(gram - style_gram)\n",
    "\n",
    "     # Overall loss\n",
    "    loss =  content_loss + style_loss\n",
    "\n",
    "    #opt = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "          #loss, method='L-BFGS-B', options={'maxiter': 10000})\n",
    "    opt = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "    # Optimization\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        # initial = x.eval()\n",
    "        # initial = initial.reshape(n_channels_frequency,n_samples_time)\n",
    "        \n",
    "        print('Started optimization.')\n",
    "        for i in range(5000):\n",
    "            print(i)\n",
    "            sess.run(opt)\n",
    "            print(sess.run(loss))\n",
    "            \n",
    "        #opt.minimize(sess)\n",
    "\n",
    "        print ('Final loss:', loss.eval())\n",
    "        result = x.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.reshape(n_channels_frequency,n_samples_time)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Result')\n",
    "plt.imshow(result[:400,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_utils = AudioUtils()\n",
    "a_content, sampling_rate = audio_utils.wave_to_spectrogram(content_filename,2048)\n",
    "a_style, sampling_rate = audio_utils.wave_to_spectrogram(style_filename,2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_time = a_content.shape[1] # considering time domain as samples\n",
    "n_channels_frequency = a_content.shape[0] # considering frequency domain as channels\n",
    "a_style = a_style[:n_channels_frequency, :n_samples_time] # making sure style and content tensors have same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_utils.spectrogram_to_wave(result , 2048 , \"out3.wav\", sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(\"out3.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(content_filename))\n",
    "display(Audio(style_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(sum(np.square(result - a_content)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(sum(np.square(result - a_style)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_style, sampling_rate = audio_utils.wave_to_spectrogram('/Users/durveshvedak/PycharmProjects/DeepAudioStyleTransfer/out.wav',2048)\n",
    "a_content, sampling_rate = audio_utils.wave_to_spectrogram('/Users/durveshvedak/Desktop/Fall 2018/Deep Learning/AudioTrainedNetwork/applause2.wav',2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_time = a_content.shape[1] # considering time domain as samples\n",
    "n_channels_frequency = a_content.shape[0] # considering frequency domain as channels\n",
    "a_style = a_style[:n_channels_frequency, :n_samples_time] # making sure style and content tensors have same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.title('Result')\n",
    "plt.imshow(a_style[:400,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
